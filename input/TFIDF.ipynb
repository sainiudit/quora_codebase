{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import re\n",
    "import cPickle as pickle\n",
    "\n",
    "from nltk.stem.porter import *\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.stem import wordnet\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "from tsne import bh_sne\n",
    "from gensim.models import Word2Vec\n",
    "stops = set([\"http\",\"www\",\"img\",\"border\",\"home\",\"body\",\"a\",\"about\",\"above\",\"after\",\"again\",\"against\",\"all\",\"am\",\"an\",\n",
    "\"and\",\"any\",\"are\",\"aren't\",\"as\",\"at\",\"be\",\"because\",\"been\",\"before\",\"being\",\"below\",\"between\",\"both\",\"but\",\"by\",\"can't\",\n",
    "\"cannot\",\"could\",\"couldn't\",\"did\",\"didn't\",\"do\",\"does\",\"doesn't\",\"doing\",\"don't\",\"down\",\"during\",\"each\",\"few\",\"for\",\"from\",\n",
    "\"further\",\"had\",\"hadn't\",\"has\",\"hasn't\",\"have\",\"haven't\",\"having\",\"he\",\"he'd\",\"he'll\",\"he's\",\"her\",\"here\",\"here's\",\"hers\",\n",
    "\"herself\",\"him\",\"himself\",\"his\",\"how\",\"how's\",\"i\",\"i'd\",\"i'll\",\"i'm\",\"i've\",\"if\",\"in\",\"into\",\"is\",\"isn't\",\"it\",\"it's\",\"its\",\n",
    "\"itself\",\"let's\",\"me\",\"more\",\"most\",\"mustn't\",\"my\",\"myself\",\"no\",\"nor\",\"not\",\"of\",\"off\",\"on\",\"once\",\"only\",\"or\",\"other\",\"ought\",\n",
    "\"our\",\"ours\",\"ourselves\",\"out\",\"over\",\"own\",\"same\",\"shan't\",\"she\",\"she'd\",\"she'll\",\"she's\",\"should\",\"shouldn't\",\"so\",\"some\",\"such\",\n",
    "\"than\",\"that\",\"that's\",\"the\",\"their\",\"theirs\",\"them\",\"themselves\",\"then\",\"there\",\"there's\",\"these\",\"they\",\"they'd\",\"they'll\",\"they're\",\n",
    "\"they've\",\"this\",\"those\",\"through\",\"to\",\"too\",\"under\",\"until\",\"up\",\"very\",\"was\",\"wasn't\",\"we\",\"we'd\",\"we'll\",\"we're\",\"we've\",\"were\",\n",
    "\"weren't\",\"what\",\"what's\",\"when\",\"when's\"\"where\",\"where's\",\"which\",\"while\",\"who\",\"who's\",\"whom\",\"why\",\"why's\",\"with\",\"won't\",\"would\",\n",
    "\"wouldn't\",\"you\",\"you'd\",\"you'll\",\"you're\",\"you've\",\"your\",\"yours\",\"yourself\",\"yourselves\" ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"train_porter.csv\",encoding='utf-8').fillna('')\n",
    "test=pd.read_csv(\"test_porter.csv\",encoding='utf-8').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(ngram_range=(1,2), min_df=3,stop_words=stops,max_features=100000)\n",
    "X_tf = vect.fit_transform(list(test['question2_porter'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=100, n_iter=15)\n",
    "X_svd = svd.fit_transform(X_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.to_pickle(X_svd,'test_q2_svd.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#logging.info('tSNE part')\n",
    "#logging.info('\\t [1\\3] process title')\n",
    "svd = TruncatedSVD(n_components=100, n_iter=15)\n",
    "X_svd = svd.fit_transform(X_tf)\n",
    "pd.to_pickle(X_svd,'test_q2_svd.pkl')\n",
    "X_scaled = StandardScaler().fit_transform(X_svd)\n",
    "#X_tsne = bh_sne(X_scaled)\n",
    "#pd.to_pickle(X_tsne,'test_q2_tsne.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#logging.info('tSNE part')\n",
    "#logging.info('\\t [1\\3] process title')\n",
    "#vect = TfidfVectorizer(ngram_range=(1,2), min_df=3,stop_words=stops,max_features=100000)\n",
    "#X_tf = vect.fit_transform(list(train['question1_porter'].values))\n",
    "\n",
    "svd = TruncatedSVD(n_components=100, n_iter=15)\n",
    "X_svd = svd.fit_transform(X_tf)\n",
    "pd.to_pickle(X_svd,'train_q1_svd.pkl')\n",
    "#X_scaled = StandardScaler().fit_transform(X_svd)\n",
    "#X_tsne = bh_sne(X_scaled)\n",
    "#pd.to_pickle(X_tsne,'train_q1_tsne.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#logging.info('tSNE part')\n",
    "#logging.info('\\t [1\\3] process title')\n",
    "vect = TfidfVectorizer(ngram_range=(1,2), min_df=3,stop_words=stops,max_features=100000)\n",
    "X_tf = vect.fit_transform(list(train['question2_porter'].values))\n",
    "\n",
    "svd = TruncatedSVD(n_components=100, n_iter=15)\n",
    "X_svd = svd.fit_transform(X_tf)\n",
    "pd.to_pickle(X_svd,'train_q2_svd.pkl')\n",
    "#X_scaled = StandardScaler().fit_transform(X_svd)\n",
    "#X_tsne = bh_sne(X_scaled)\n",
    "#pd.to_pickle(X_tsne,'train_q2_tsne.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#logging.info('tSNE part')\n",
    "#logging.info('\\t [1\\3] process title')\n",
    "#vect = TfidfVectorizer(ngram_range=(1,2), min_df=3,stop_words=stops,max_features=100000)\n",
    "#X_tf = vect.fit_transform(list(test['question1_porter'].values))\n",
    "\n",
    "svd = TruncatedSVD(n_components=100, n_iter=15)\n",
    "X_svd = svd.fit_transform(X_tf)\n",
    "pd.to_pickle(X_svd,'test_q1_svd.pkl')\n",
    "#X_scaled = StandardScaler().fit_transform(X_svd)\n",
    "#X_tsne = bh_sne(X_scaled)\n",
    "#pd.to_pickle(X_tsne,'test_q1_tsne.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_scaled = StandardScaler().fit_transform(X_svd)\n",
    "X_tsne = bh_sne(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.to_pickle(X_tsne,'test_q1_tsne.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
